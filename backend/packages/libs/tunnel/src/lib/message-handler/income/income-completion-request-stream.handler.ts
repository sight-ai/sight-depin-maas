import { Inject, Injectable, Logger } from '@nestjs/common';
import { IncomeBaseMessageHandler } from '../base-message-handler';
import {
  TunnelMessage,
  CompletionCompatibilityPayload,
  CompletionRequestStreamMessage,
  CompletionResponseStreamMessage
} from '@saito/models';
import { MessageHandler } from '../message-handler.decorator';
import { TunnelService } from '../../tunnel.interface';
import { UnifiedModelService } from '@saito/model-inference-client';

// ä½¿ç”¨ models ä¸­å®šä¹‰çš„ç±»å‹ï¼Œæ— éœ€æœ¬åœ°å®šä¹‰

/**
 * OpenAI æµå¼ Completion è¯·æ±‚å¤„ç†å™¨
 * 
 * èŒè´£ï¼š
 * 1. æ¥æ”¶å¹¶éªŒè¯æµå¼ completion è¯·æ±‚
 * 2. è°ƒç”¨æ¨ç†æœåŠ¡æ‰§è¡Œæ–‡æœ¬è¡¥å…¨
 * 3. å¤„ç† OpenAI SSE æ ¼å¼çš„æµå¼å“åº”
 * 4. è½¬å‘å“åº”ç»™ç›®æ ‡è®¾å¤‡
 * 
 * è®¾è®¡æ¨¡å¼ï¼š
 * - Strategy Pattern: å¤„ç†ä¸åŒæ ¼å¼çš„æµå¼æ•°æ®
 * - Template Method: æ ‡å‡†åŒ–æ¶ˆæ¯å¤„ç†æµç¨‹
 * - Factory Pattern: åˆ›å»ºå“åº”å¤„ç†å™¨
 */
@MessageHandler({ type: 'completion_request_stream', direction: 'income' })
@Injectable()
export class IncomeCompletionRequestStreamHandler extends IncomeBaseMessageHandler {
  private readonly logger = new Logger(IncomeCompletionRequestStreamHandler.name);

  // SSE æ•°æ®ç¼“å†²åŒº - ç”¨äºå¤„ç†ä¸å®Œæ•´çš„ SSE è¡Œ
  private readonly sseBuffers = new Map<string, string>();

  constructor(
    @Inject('TunnelService') private readonly tunnel: TunnelService,
    private readonly unifiedModelService: UnifiedModelService
  ) {
    super();
  }

  /**
   * å¤„ç†å…¥ç«™æµå¼ completion è¯·æ±‚æ¶ˆæ¯
   * Template Method Pattern - å®šä¹‰æ ‡å‡†å¤„ç†æµç¨‹
   */
  async handleIncomeMessage(message: TunnelMessage): Promise<void> {
    this.logger.log(`ğŸ¯ æ”¶åˆ°æµå¼ Completion è¯·æ±‚ - ç›®æ ‡: ${message.to}, æ¥æº: ${message.from}`);

    try {
      // 1. éªŒè¯å¹¶è§£ææ¶ˆæ¯
      const completionRequest = this.parseAndValidateMessage(message);

      // 2. æ‰§è¡Œæµå¼ completion æ¨ç†
      await this.processCompletionRequestStream(completionRequest);

    } catch (error) {
      this.logger.error(`âŒ å¤„ç†æµå¼ Completion è¯·æ±‚å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
      await this.handleError(message, error);
    }
  }

  /**
   * è§£æå¹¶éªŒè¯æ¶ˆæ¯
   * Strategy Pattern - æ”¯æŒå¤šç§æ¶ˆæ¯æ ¼å¼
   */
  private parseAndValidateMessage(message: TunnelMessage): CompletionRequestStreamMessage {
    // å°è¯•ç›´æ¥è§£æä¸ºæ ‡å‡†æ ¼å¼
    if (message.type === 'completion_request_stream' && message.payload) {
      const payload = message.payload as any;
      if (payload.taskId && payload.data) {
        this.logger.debug(`âœ… æ ‡å‡†æ ¼å¼è§£ææˆåŠŸ`);
        return message as CompletionRequestStreamMessage;
      }
    }

    // å°è¯•å…¼å®¹æ ¼å¼è§£æ
    this.logger.debug(`âš ï¸ å°è¯•å…¼å®¹æ ¼å¼è§£æ`);
    return this.parseCompatibilityFormat(message);
  }

  /**
   * è§£æå…¼å®¹æ ¼å¼çš„æ¶ˆæ¯ï¼ˆåµŒå¥— data æ ¼å¼ï¼‰
   */
  private parseCompatibilityFormat(message: TunnelMessage): CompletionRequestStreamMessage {
    const payload = message.payload as CompletionCompatibilityPayload;

    if (!payload.taskId || !payload.data) {
      throw new Error('Invalid compatibility format: missing taskId or data');
    }

    // è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    const convertedData = {
      model: payload.data.model || 'unknown',
      prompt: payload.data.prompt,
      stream: true, // ç¡®ä¿æ˜¯æµå¼è¯·æ±‚
      temperature: payload.data.temperature,
      max_tokens: payload.data.max_tokens,
      top_p: payload.data.top_p,
      frequency_penalty: payload.data.frequency_penalty,
      presence_penalty: payload.data.presence_penalty,
      stop: payload.data.stop,
      n: payload.data.n || 1,
      logit_bias: payload.data.logit_bias,
      user: payload.data.user,
      echo: payload.data.echo,
      logprobs: payload.data.logprobs
    };

    // è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    return {
      type: 'completion_request_stream',
      from: message.from,
      to: message.to,
      payload: {
        taskId: payload.taskId,
        path: payload.path || '/openai/v1/completions',
        data: convertedData
      }
    };
  }

  /**
   * å¤„ç†é”™è¯¯æƒ…å†µ
   */
  private async handleError(message: TunnelMessage, error: unknown): Promise<void> {
    const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';

    this.logger.error(`å¤„ç†æ¶ˆæ¯å¤±è´¥: ${errorMessage}`, {
      messageType: message.type,
      from: message.from,
      to: message.to
    });
  }

  /**
   * å¤„ç†æµå¼ completion è¯·æ±‚å¹¶æ‰§è¡Œæ¨ç†
   */
  private async processCompletionRequestStream(message: CompletionRequestStreamMessage): Promise<void> {
    const payload = message.payload;
    const taskId = payload.taskId;
    const path = payload.path;

    // ä» payload ä¸­æå– OpenAI æ ¼å¼çš„æ•°æ®
    const requestData = payload.data;

    // æ„å»ºè¯·æ±‚å‚æ•°ï¼Œç¡®ä¿æ˜¯æµå¼è¯·æ±‚
    const requestParams = {
      model: requestData.model,
      prompt: Array.isArray(requestData.prompt) ? requestData.prompt.join('\n') : requestData.prompt,
      stream: true, // ç¡®ä¿æ˜¯æµå¼è¯·æ±‚
      temperature: requestData.temperature,
      max_tokens: requestData.max_tokens,
      top_p: requestData.top_p,
      frequency_penalty: requestData.frequency_penalty,
      presence_penalty: requestData.presence_penalty,
      stop: requestData.stop,
      n: requestData.n,
      echo: requestData.echo,
      logprobs: requestData.logprobs
    };

    this.logger.log(`æ‰§è¡Œæµå¼ Completion æ¨ç† - TaskID: ${taskId}, Path: ${path}, Model: ${requestParams.model}`);

    // éªŒè¯è¯·æ±‚æ•°æ®
    this.validateCompletionRequest(requestParams);

    this.logger.debug(`è°ƒç”¨æ¨ç†æœåŠ¡ - Model: ${requestParams.model}, Prompt: ${typeof requestParams.prompt === 'string' ? requestParams.prompt.substring(0, 100) : 'Array'}`);

    try {
      // åˆ›å»ºæµå¼å“åº”å¤„ç†å™¨
      const responseHandler = this.createStreamResponseHandler(taskId, message.from);

      // è°ƒç”¨æ¨ç†æœåŠ¡
      await this.unifiedModelService.complete(requestParams, responseHandler as unknown as any, path);

    } catch (error) {
      this.logger.error(`æ¨ç†æ‰§è¡Œå¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
      throw error;
    }
  }

  /**
   * éªŒè¯ completion è¯·æ±‚æ•°æ®
   */
  private validateCompletionRequest(data: any): void {
    if (!data.prompt || (Array.isArray(data.prompt) && data.prompt.length === 0)) {
      throw new Error('Invalid completion request: missing prompt');
    }

    if (!data.model) {
      throw new Error('Invalid completion request: missing model');
    }
  }

  /**
   * åˆ›å»ºæµå¼å“åº”å¤„ç†å™¨
   * Factory Pattern - åˆ›å»ºæ¨¡æ‹Ÿçš„ Express Response å¯¹è±¡
   */
  private createStreamResponseHandler(taskId: string, targetDeviceId: string) {
    return {
      // Express Response æ¥å£æ–¹æ³•
      setHeader: () => { },
      status: () => ({ json: () => { } }),
      json: () => { },
      headersSent: false,

      // æµå¼å†™å…¥æ–¹æ³•
      write: async (chunk: any) => {
        try {
          let jsonData: any;

          // å¦‚æœå·²ç»æ˜¯å¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨
          if (typeof chunk === 'object' && chunk !== null && !Buffer.isBuffer(chunk) && !(chunk instanceof Uint8Array)) {
            jsonData = chunk;
          } else {
            // è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶è§£æ JSON
            const text = chunk instanceof Uint8Array
              ? new TextDecoder('utf-8').decode(chunk)
              : String(chunk);
              console.log(text)
            jsonData = text.includes('data: [DONE]') ? {
              id: `cmpl-${taskId}`,
              object: 'text_completion',
              created: Math.floor(Date.now() / 1000),
              model: 'unknown',
              choices: [{
                text: '',
                index: 0,
                finish_reason: 'stop'
              }]
            } :JSON.parse(text.replace('data: ', ''));
          }

          // å‘é€ JSON æ•°æ®
          await this.sendStreamChunk(taskId, targetDeviceId, jsonData);

        } catch (error) {
          this.logger.error(`æ•°æ®å—è§£æå¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
        }
      },

      // æµå¼ç»“æŸæ–¹æ³•
      end: async () => {
        await this.sendStreamComplete(taskId, targetDeviceId);
      }
    };
  }
  /**
   * å‘é€æµå¼æ•°æ®å—ï¼ˆOpenAI Completion æ ¼å¼ï¼‰
   */
  private async sendStreamChunk(taskId: string, targetDeviceId: string, chunk: any): Promise<void> {
    this.logger.debug(`ğŸ“¤ å‘é€ OpenAI Completion æ•°æ®å— - TaskID: ${taskId}`);

    const streamMessage: CompletionResponseStreamMessage = {
      type: 'completion_response_stream',
      from: this.peerId,
      to: targetDeviceId,
      payload: {
        taskId,
        path: '', // å“åº”æ—¶pathå¯ä»¥ä¸ºç©º
        data: chunk
      }
    };

    // ä½¿ç”¨ handleMessage è®©ç³»ç»Ÿè‡ªåŠ¨åˆ¤æ–­å‘é€ç›®æ ‡
    await this.tunnel.handleMessage(streamMessage as any);
  }

  /**
   * å‘é€æµå¼å®Œæˆä¿¡å·
   */
  private async sendStreamComplete(taskId: string, targetDeviceId: string): Promise<void> {
    // æ¸…ç† SSE ç¼“å†²åŒº
    const bufferKey = `${taskId}-${targetDeviceId}`;
    this.sseBuffers.delete(bufferKey);

    this.logger.log(`âœ… æµå¼ Completion æ¨ç†å®Œæˆ - TaskID: ${taskId}, Target: ${targetDeviceId}`);

    // åˆ›å»ºç¬¦åˆ OpenAI æ ¼å¼çš„å®Œæˆä¿¡å·
    const completeChunk = {
      id: `cmpl-${taskId}`,
      object: 'text_completion',
      created: Math.floor(Date.now() / 1000),
      model: 'unknown',
      choices: [{
        text: '',
        index: 0,
        finish_reason: 'stop'
      }]
    };

    const completeMessage: CompletionResponseStreamMessage = {
      type: 'completion_response_stream',
      from: this.peerId,
      to: targetDeviceId,
      payload: {
        taskId,
        path: '', // å“åº”æ—¶pathå¯ä»¥ä¸ºç©º
        data: completeChunk,
        done: true
      }
    };

    // ä½¿ç”¨ handleMessage è®©ç³»ç»Ÿè‡ªåŠ¨åˆ¤æ–­å‘é€ç›®æ ‡
    await this.tunnel.handleMessage(completeMessage as any);
  }
}
