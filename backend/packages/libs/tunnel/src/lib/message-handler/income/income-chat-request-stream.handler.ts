import { Inject, Injectable, Logger } from '@nestjs/common';
import { EventEmitter2, OnEvent } from '@nestjs/event-emitter';
import { IncomeBaseMessageHandler } from '../base-message-handler';
import {
  TunnelMessage,
  ChatRequestStreamMessage,
  ChatRequestStreamMessageSchema,
  ChatResponseStreamMessage,
  ChatCompatibilityPayload,
  OpenAIChatCompletionChunk,
  OpenAIChatCompletionRequest,
  OpenAIChatCompletionChunkSchema,
  OpenAIChatMessage
} from '@saito/models';
import { MessageHandler } from '../message-handler.decorator';
import { TunnelService } from '../../tunnel.interface';
import {
  TUNNEL_EVENTS,
  TunnelChatRequestReceivedEvent,
  TunnelChatInferenceRequestEvent,
  TunnelInferenceResponseEvent
} from '../../events';

// ä½¿ç”¨ models ä¸­å®šä¹‰çš„ç±»å‹ï¼Œæ— éœ€æœ¬åœ°å®šä¹‰

/**
 * OpenAI æµå¼èŠå¤©è¯·æ±‚å¤„ç†å™¨
 *
 * èŒè´£ï¼š
 * 1. æ¥æ”¶å¹¶éªŒè¯æµå¼èŠå¤©è¯·æ±‚
 * 2. è°ƒç”¨æ¨ç†æœåŠ¡æ‰§è¡ŒèŠå¤©
 * 3. å¤„ç† OpenAI SSE æ ¼å¼çš„æµå¼å“åº”
 * 4. è½¬å‘å“åº”ç»™ç›®æ ‡è®¾å¤‡
 *
 * è®¾è®¡æ¨¡å¼ï¼š
 * - Strategy Pattern: å¤„ç†ä¸åŒæ ¼å¼çš„æµå¼æ•°æ®
 * - Template Method: æ ‡å‡†åŒ–æ¶ˆæ¯å¤„ç†æµç¨‹
 * - Factory Pattern: åˆ›å»ºå“åº”å¤„ç†å™¨
 */
@MessageHandler({ type: 'chat_request_stream', direction: 'income' })
@Injectable()
export class IncomeChatRequestStreamHandler extends IncomeBaseMessageHandler {
  private readonly logger = new Logger(IncomeChatRequestStreamHandler.name);

  // SSE æ•°æ®ç¼“å†²åŒº - ç”¨äºå¤„ç†ä¸å®Œæ•´çš„ SSE è¡Œ
  private readonly sseBuffers = new Map<string, string>();

  constructor(
    @Inject('TunnelService') private readonly tunnel: TunnelService,
    private readonly eventEmitter: EventEmitter2
  ) {
    super();
  }

  /**
   * å¤„ç†å…¥ç«™æµå¼èŠå¤©è¯·æ±‚æ¶ˆæ¯
   * Template Method Pattern - å®šä¹‰æ ‡å‡†å¤„ç†æµç¨‹
   */
  async handleIncomeMessage(message: TunnelMessage): Promise<void> {
    this.logger.log(`ğŸ¯ æ”¶åˆ°æµå¼èŠå¤©è¯·æ±‚ - ç›®æ ‡: ${message.to}, æ¥æº: ${message.from}`);

    try {
      // 1. éªŒè¯å¹¶è§£ææ¶ˆæ¯
      const chatRequest = this.parseAndValidateMessage(message);

      // å‘å°„èŠå¤©è¯·æ±‚æ¥æ”¶äº‹ä»¶
      this.eventEmitter.emit(
        TUNNEL_EVENTS.CHAT_REQUEST_RECEIVED,
        new TunnelChatRequestReceivedEvent(
          chatRequest.payload.taskId || `${Date.now()}`,
          chatRequest.from,
          chatRequest.payload,
          true // æµå¼è¯·æ±‚
        )
      );

      // 2. æ‰§è¡Œæµå¼èŠå¤©æ¨ç†
      await this.processChatRequestStream(chatRequest);

    } catch (error) {
      this.logger.error(`âŒ å¤„ç†æµå¼èŠå¤©è¯·æ±‚å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
      await this.handleError(message, error);
    }
  }

  /**
   * è§£æå¹¶éªŒè¯æ¶ˆæ¯
   * Strategy Pattern - æ”¯æŒå¤šç§æ¶ˆæ¯æ ¼å¼
   */
  private parseAndValidateMessage(message: TunnelMessage): ChatRequestStreamMessage {
    // å°è¯•æ ‡å‡†æ ¼å¼è§£æ
    const parseResult = ChatRequestStreamMessageSchema.safeParse(message);

    if (parseResult.success) {
      this.logger.debug(`âœ… æ ‡å‡†æ ¼å¼è§£ææˆåŠŸ`);
      return parseResult.data;
    }

    // å°è¯•å…¼å®¹æ ¼å¼è§£æ
    this.logger.debug(`âš ï¸ æ ‡å‡†æ ¼å¼è§£æå¤±è´¥ï¼Œå°è¯•å…¼å®¹æ ¼å¼: ${parseResult.error.message}`);
    return this.parseCompatibilityFormat(message);
  }

  /**
   * è§£æå…¼å®¹æ ¼å¼çš„æ¶ˆæ¯ï¼ˆåµŒå¥— data æ ¼å¼ï¼‰
   */
  private parseCompatibilityFormat(message: TunnelMessage): ChatRequestStreamMessage {
    const payload = message.payload as ChatCompatibilityPayload;

    if (!payload.taskId || !payload.data) {
      throw new Error('Invalid compatibility format: missing taskId or data');
    }

    // è½¬æ¢æ¶ˆæ¯æ ¼å¼ä»¥ç¬¦åˆ OpenAI æ ‡å‡†
    const convertedMessages: OpenAIChatMessage[] = payload.data.messages.map(msg => ({
      role: msg.role as 'system' | 'user' | 'assistant' | 'function',
      content: msg.content || null,
      name: undefined,
      function_call: undefined
    }));

    const convertedData: OpenAIChatCompletionRequest = {
      model: payload.data.model || 'unknown',
      messages: convertedMessages,
      stream: payload.data.stream !== false,
      temperature: payload.data.temperature,
      max_tokens: payload.data.max_tokens,
      top_p: payload.data.top_p,
      frequency_penalty: payload.data.frequency_penalty,
      presence_penalty: payload.data.presence_penalty,
      stop: payload.data.stop,
      n: payload.data.n || 1, // æä¾›é»˜è®¤å€¼
      logit_bias: payload.data.logit_bias,
      user: payload.data.user
    };

    // è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    return {
      type: 'chat_request_stream',
      from: message.from,
      to: message.to,
      payload: {
        taskId: payload.taskId,
        path: payload.path || '/openai/v1/chat/completions',
        data: convertedData as any // ä¸´æ—¶ç±»å‹æ–­è¨€ï¼Œè§£å†³å…¼å®¹æ€§é—®é¢˜
      }
    };
  }

  /**
   * å¤„ç†é”™è¯¯æƒ…å†µ
   */
  private async handleError(message: TunnelMessage, error: unknown): Promise<void> {
    const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';

    // è¿™é‡Œå¯ä»¥å‘é€é”™è¯¯å“åº”ç»™å®¢æˆ·ç«¯
    this.logger.error(`å¤„ç†æ¶ˆæ¯å¤±è´¥: ${errorMessage}`, {
      messageType: message.type,
      from: message.from,
      to: message.to
    });
  }

  /**
   * å¤„ç†æµå¼èŠå¤©è¯·æ±‚ - çº¯äº‹ä»¶é©±åŠ¨æ–¹å¼
   *
   * èŒè´£ï¼š
   * 1. éªŒè¯è¯·æ±‚æ•°æ®
   * 2. å‘å°„æ¨ç†è¯·æ±‚äº‹ä»¶
   * 3. ä¸ç›´æ¥è°ƒç”¨æ¨ç†æœåŠ¡ï¼ˆè§£è€¦ï¼‰
   */
  private async processChatRequestStream(message: ChatRequestStreamMessage): Promise<void> {
    const payload = message.payload;
    const taskId = payload.taskId;
    const path = payload.path;

    // ä» payload ä¸­æå– OpenAI æ ¼å¼çš„æ•°æ®
    const requestData = payload.data as OpenAIChatCompletionRequest;

    // æ„å»ºè¯·æ±‚å‚æ•°ï¼Œç¡®ä¿æ˜¯æµå¼è¯·æ±‚
    const requestParams: OpenAIChatCompletionRequest = {
      ...requestData,
      stream: true // ç¡®ä¿æ˜¯æµå¼è¯·æ±‚
    };

    this.logger.log(`ğŸ¯ å‡†å¤‡å‘å°„æµå¼èŠå¤©æ¨ç†è¯·æ±‚äº‹ä»¶ - TaskID: ${taskId}, Path: ${path}, Model: ${requestParams.model}`);

    // éªŒè¯è¯·æ±‚æ•°æ®
    this.validateChatRequest(requestParams);

    try {
      // å‘å°„èŠå¤©æ¨ç†è¯·æ±‚äº‹ä»¶ï¼Œè®©æ¨ç†æœåŠ¡æ¨¡å—å¤„ç†
      // Tunnel æ¨¡å—åªè´Ÿè´£æ¶ˆæ¯ä¼ è¾“ï¼Œä¸ç›´æ¥è°ƒç”¨æ¨ç†æœåŠ¡
      this.eventEmitter.emit(
        TUNNEL_EVENTS.CHAT_INFERENCE_REQUEST,
        new TunnelChatInferenceRequestEvent(
          taskId,
          message.from,
          requestParams,
          path,
          true // æµå¼è¯·æ±‚
        )
      );

      this.logger.log(`âœ… å·²å‘å°„èŠå¤©æ¨ç†è¯·æ±‚äº‹ä»¶ - TaskID: ${taskId}`);
      this.logger.debug(`ğŸ“¡ äº‹ä»¶å·²å‘å°„ï¼Œç­‰å¾…æ¨ç†æœåŠ¡æ¨¡å—å¤„ç†å¹¶å“åº”`);

    } catch (error) {
      this.logger.error(`âŒ å‘å°„æ¨ç†è¯·æ±‚äº‹ä»¶å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
      throw error;
    }
  }

  /**
   * éªŒè¯èŠå¤©è¯·æ±‚æ•°æ®
   */
  private validateChatRequest(data: OpenAIChatCompletionRequest): void {
    if (!data.messages || data.messages.length === 0) {
      throw new Error('Invalid chat request: missing messages');
    }

    if (!data.model) {
      throw new Error('Invalid chat request: missing model');
    }
  }

  // æ³¨æ„ï¼šæ¨ç†å“åº”ç›‘å¬å™¨å·²ç§»é™¤
  // ç°åœ¨æ¨ç†æœåŠ¡ç›´æ¥é€šè¿‡ tunnel å‘é€å“åº”ï¼Œä¸å†éœ€è¦äº‹ä»¶è½¬å‘

  /**
   * åˆ›å»ºæµå¼å“åº”å¤„ç†å™¨
   * Factory Pattern - åˆ›å»ºæ¨¡æ‹Ÿçš„ Express Response å¯¹è±¡
   */
  private createStreamResponseHandler(taskId: string, targetDeviceId: string) {
    return {
      // Express Response æ¥å£æ–¹æ³•
      setHeader: () => {},
      status: () => ({ json: () => {} }),
      json: () => {},
      headersSent: false,

      // æµå¼å†™å…¥æ–¹æ³•
      write: async (chunk: string | Buffer | object) => {
        try {
          const text = this.convertChunkToText(chunk);
          console.log(text)
          if (text) {
            await this.handleOpenAISSEChunk(taskId, targetDeviceId, text);
          } else if (typeof chunk === 'object') {
            // éªŒè¯å¹¶å¤„ç†å¯¹è±¡ç±»å‹çš„æ•°æ®
            const validatedChunk = this.validateOpenAIChunk(chunk);
            if (validatedChunk) {
              await this.sendStreamChunk(taskId, targetDeviceId, validatedChunk);
            }
          }
        } catch (error) {
          this.logger.error(`å¤„ç†æ•°æ®å—å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
        }
      },

      // æµå¼ç»“æŸæ–¹æ³•
      end: async () => {
        await this.sendStreamComplete(taskId, targetDeviceId);
      }
    };
  }

  /**
   * å°†æ•°æ®å—è½¬æ¢ä¸ºæ–‡æœ¬
   * Strategy Pattern - å¤„ç†ä¸åŒç±»å‹çš„æ•°æ®å—
   */
  private convertChunkToText(chunk: string | Buffer | object): string | null {
    if (typeof chunk === 'string') {
      return chunk;
    }

    if (Buffer.isBuffer(chunk)) {
      return chunk.toString('utf8');
    }

    if (chunk && typeof chunk === 'object') {
      // æ£€æŸ¥æ˜¯å¦æ˜¯ç±»æ•°ç»„å¯¹è±¡
      if (Array.isArray(chunk) || ('length' in chunk && typeof (chunk as ArrayLike<number>).length === 'number')) {
        const uint8Array = new Uint8Array(chunk as ArrayLike<number>);
        return Buffer.from(uint8Array).toString('utf8');
      }
    }

    return String(chunk);
  }

  /**
   * å¤„ç† OpenAI SSE æµå¼æ•°æ®å—å¹¶è½¬æ¢ä¸º JSON
   * Strategy Pattern - ä¸“é—¨å¤„ç† SSE æ ¼å¼æ•°æ®
   */
  private async handleOpenAISSEChunk(taskId: string, targetDeviceId: string, text: string): Promise<void> {
    try {
      const bufferKey = `${taskId}-${targetDeviceId}`;
      let buffer = this.sseBuffers.get(bufferKey) || '';

      // ç´¯ç§¯æ•°æ®
      buffer += text;

      // æŒ‰è¡Œåˆ†å‰²å¤„ç† SSE æ•°æ®
      const lines = buffer.split('\n');
      let processedLines = 0;

      for (let i = 0; i < lines.length - 1; i++) { // ä¿ç•™æœ€åä¸€è¡Œï¼Œå¯èƒ½ä¸å®Œæ•´
        const line = lines[i].trim();

        if (line.startsWith('data: ')) {
          const data = line.slice(6); // ç§»é™¤ "data: " å‰ç¼€

          if (data === '[DONE]') {
            await this.sendStreamComplete(taskId, targetDeviceId);
            this.sseBuffers.delete(bufferKey);
            return;
          }

          try {
            // è§£æå¹¶éªŒè¯ OpenAI æ ¼å¼æ•°æ®
            const jsonData = JSON.parse(data);
            const validatedChunk = this.validateOpenAIChunk(jsonData);

            if (validatedChunk) {
              await this.sendStreamChunk(taskId, targetDeviceId, validatedChunk);
            }

            processedLines = i + 1;
          } catch (parseError) {
            this.logger.warn(`è§£æ OpenAI SSE æ•°æ®å¤±è´¥: ${data}`);
            processedLines = i + 1;
          }
        } else if (line === '' || line.startsWith(':')) {
          // ç©ºè¡Œæˆ–æ³¨é‡Šè¡Œï¼Œè·³è¿‡
          processedLines = i + 1;
        } else {
          processedLines = i + 1;
        }
      }

      // æ›´æ–°ç¼“å†²åŒº
      const remainingBuffer = lines.slice(processedLines).join('\n');
      if (remainingBuffer.trim()) {
        this.sseBuffers.set(bufferKey, remainingBuffer);
      } else {
        this.sseBuffers.delete(bufferKey);
      }

    } catch (error) {
      this.logger.error(`å¤„ç† OpenAI SSE æ•°æ®å—å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
    }
  }

  /**
   * éªŒè¯ OpenAI æ•°æ®å—æ ¼å¼
   */
  private validateOpenAIChunk(data: unknown): OpenAIChatCompletionChunk | null {
    try {
      const result = OpenAIChatCompletionChunkSchema.safeParse(data);
      if (result.success) {
        return result.data;
      } else {
        this.logger.warn(`OpenAI æ•°æ®å—æ ¼å¼éªŒè¯å¤±è´¥: ${result.error.message}`);
        return null;
      }
    } catch (error) {
      this.logger.warn(`OpenAI æ•°æ®å—éªŒè¯å¼‚å¸¸: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
      return null;
    }
  }






  /**
   * å‘é€æµå¼æ•°æ®å—ï¼ˆOpenAI æ ¼å¼ï¼‰
   * ä½¿ç”¨æ­£ç¡®çš„ Zod ç±»å‹éªŒè¯
   */
  private async sendStreamChunk(taskId: string, targetDeviceId: string, chunk: OpenAIChatCompletionChunk): Promise<void> {
    this.logger.debug(`ğŸ“¤ å‘é€ OpenAI æ•°æ®å— - TaskID: ${taskId}, Model: ${chunk.model}`);

    const streamMessage: ChatResponseStreamMessage = {
      type: 'chat_response_stream',
      from: this.peerId,
      to: targetDeviceId,
      payload: {
        taskId,
        path: '', // å“åº”æ—¶pathå¯ä»¥ä¸ºç©º
        data: chunk // åŒæ—¶ä¿æŒ data å­—æ®µå…¼å®¹æ€§
      } as any // ä¸´æ—¶ä½¿ç”¨ anyï¼Œå› ä¸ºç±»å‹å®šä¹‰éœ€è¦æ›´æ–°
    };

    // ä½¿ç”¨ handleMessage è®©ç³»ç»Ÿè‡ªåŠ¨åˆ¤æ–­å‘é€ç›®æ ‡
    await this.tunnel.handleMessage(streamMessage);
  }

  /**
   * å‘é€æµå¼å®Œæˆä¿¡å·
   */
  private async sendStreamComplete(taskId: string, targetDeviceId: string): Promise<void> {
    // æ¸…ç† SSE ç¼“å†²åŒº
    const bufferKey = `${taskId}-${targetDeviceId}`;
    this.sseBuffers.delete(bufferKey);

    this.logger.log(`âœ… æµå¼æ¨ç†å®Œæˆ - TaskID: ${taskId}, Target: ${targetDeviceId}`);

    // åˆ›å»ºç¬¦åˆ OpenAI æ ¼å¼çš„å®Œæˆä¿¡å·
    const completeChunk: OpenAIChatCompletionChunk = {
      id: `chatcmpl-${taskId}`,
      object: 'chat.completion.chunk',
      created: Math.floor(Date.now() / 1000),
      model: 'unknown',
      choices: [{
        index: 0,
        delta: {},
        finish_reason: 'stop'
      }]
    };

    const completeMessage: ChatResponseStreamMessage = {
      type: 'chat_response_stream',
      from: this.peerId,
      to: targetDeviceId,
      payload: {
        taskId,
        path: '', // å“åº”æ—¶pathå¯ä»¥ä¸ºç©º
        data: completeChunk,
        done: true
      } as any
    };

    // ä½¿ç”¨ handleMessage è®©ç³»ç»Ÿè‡ªåŠ¨åˆ¤æ–­å‘é€ç›®æ ‡
    await this.tunnel.handleMessage(completeMessage);
  }


}
