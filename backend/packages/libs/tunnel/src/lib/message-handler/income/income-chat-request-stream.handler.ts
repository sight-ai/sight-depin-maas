import { Inject, Injectable, Logger } from '@nestjs/common';
import { IncomeBaseMessageHandler } from '../base-message-handler';
import { TunnelMessage, ChatRequestStreamMessage, ChatRequestStreamMessageSchema, ChatResponseStreamMessage, OllamaChatStreamChunk } from '@saito/models';
import { MessageHandler } from '../message-handler.decorator';
import { TunnelService } from '../../tunnel.interface';
import { UnifiedModelService } from '@saito/model-inference-client';
import { Response } from 'express';

/**
 * æµå¼èŠå¤©è¯·æ±‚å¤„ç†å™¨
 * 
 * æ¥æ”¶æµå¼èŠå¤©è¯·æ±‚å¹¶æ‰§è¡Œæ¨ç†ï¼Œæ ¹æ®pathåŒºåˆ†Ollamaæˆ–OpenAI
 */
@MessageHandler({ type: 'chat_request_stream', direction: 'income' })
@Injectable()
export class IncomeChatRequestStreamHandler extends IncomeBaseMessageHandler {
  private readonly logger = new Logger(IncomeChatRequestStreamHandler.name);

  // ç”¨äºç´¯ç§¯Ollamaæµå¼æ•°æ®çš„ç¼“å†²åŒº
  private streamBuffers = new Map<string, string>();

  constructor(
    @Inject('TunnelService') private readonly tunnel: TunnelService,
    private readonly unifiedModelService: UnifiedModelService
  ) {
    super();
  }

  /**
   * å¤„ç†å…¥ç«™æµå¼èŠå¤©è¯·æ±‚æ¶ˆæ¯
   */
  async handleIncomeMessage(message: TunnelMessage): Promise<void> {
    this.logger.log(`ğŸ¯ IncomeChatRequestStreamHandler æ”¶åˆ°æ¶ˆæ¯!`);
    this.logger.log(`å½“å‰è®¾å¤‡ID (peerId): ${this.peerId}`);
    this.logger.log(`æ¶ˆæ¯ç›®æ ‡: ${message.to}`);
    this.logger.log(`æ¶ˆæ¯æ¥æº: ${message.from}`);
    this.logger.debug(`æ”¶åˆ°æµå¼èŠå¤©è¯·æ±‚: ${JSON.stringify(message)}`);

    try {
      // æ‰§è¡Œæµå¼èŠå¤©æ¨ç†
      await this.processChatRequestStream(message as unknown as ChatRequestStreamMessage);

    } catch (error) {
      this.logger.error(`âŒ å¤„ç†æµå¼èŠå¤©è¯·æ±‚å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
      // åˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„é”™è¯¯å“åº”æ¶ˆæ¯
      const errorMessage: ChatResponseStreamMessage = {
        type: 'chat_response_stream',
        from: this.peerId,
        to: message.from,
        payload: {
          taskId: 'unknown',
          path: '',
          data: {
            message: {
              role: 'user',
              content: 'å‘ç”Ÿé”™è¯¯: ' + (error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯')
            },
            done: true
          },
          error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯',
        }
      };
      await this.sendErrorResponse(errorMessage, error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯');
    }
  }

  /**
   * å¤„ç†æµå¼èŠå¤©è¯·æ±‚å¹¶æ‰§è¡Œæ¨ç†
   */
  private async processChatRequestStream(message: ChatRequestStreamMessage): Promise<void> {
    this.logger.log(`å¤„ç†æµå¼èŠå¤©è¯·æ±‚: ${JSON.stringify(message)}`);
    const { taskId, path, data } = message.payload;

    this.logger.log(`æ‰§è¡Œæµå¼èŠå¤©æ¨ç† - TaskID: ${taskId}, Path: ${path}, Model: ${data.model}`);

    // éªŒè¯è¯·æ±‚æ•°æ®
    if (!data.messages || data.messages.length === 0) {
      throw new Error('Invalid chat request: missing messages');
    }
    this.logger.debug(`è°ƒç”¨UnifiedModelService: ${JSON.stringify(message)}`);

    try {
      // åˆ›å»ºæ¨¡æ‹Ÿçš„Responseå¯¹è±¡æ¥å¤„ç†æµå¼å“åº”
      const mockResponse = this.createStreamResponseHandler(taskId, message.from, path);

      // ç›´æ¥è°ƒç”¨UnifiedModelService
      await this.unifiedModelService.chat(data, mockResponse as unknown as Response, path);

    } catch (error) {
      this.logger.error(`æ¨ç†æ‰§è¡Œå¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
      throw error;
    }
  }

  /**
   * åˆ›å»ºæµå¼å“åº”å¤„ç†å™¨
   * æ¨¡æ‹ŸExpress Responseå¯¹è±¡ï¼Œç”¨äºå¤„ç†UnifiedModelServiceçš„æµå¼å“åº”
   */
  private createStreamResponseHandler(taskId: string, targetDeviceId: string, path: string) {
    const self = this;

    return {
      // Express Response æ¥å£æ–¹æ³•
      setHeader: () => { },
      status: () => ({ json: () => { } }),
      json: () => { },
      headersSent: false,
      // æµå¼å†™å…¥æ–¹æ³•
      write: async (chunk: Buffer) => {
        try {
          // å¤„ç†ä¸åŒç±»å‹çš„chunkï¼Œç»Ÿä¸€è½¬æ¢ä¸ºæ–‡æœ¬
          let text: string;

          if (typeof chunk === 'string') {
            text = chunk;
          } else if (Buffer.isBuffer(chunk)) {
            text = chunk.toString('utf8');
          } else if (chunk && typeof chunk === 'object') {
            // æ£€æŸ¥æ˜¯å¦æ˜¯Uint8Arrayæˆ–ç±»ä¼¼çš„æ•°å­—æ•°ç»„
            if (Array.isArray(chunk) || ('length' in chunk && typeof (chunk as ArrayLike<number>).length === 'number')) {
              // å°†æ•°å­—æ•°ç»„è½¬æ¢ä¸ºBufferç„¶åè½¬æ¢ä¸ºå­—ç¬¦ä¸²
              const uint8Array = new Uint8Array(chunk as ArrayLike<number>);
              text = Buffer.from(uint8Array).toString('utf8');
            } else {
              // å¦‚æœæ˜¯å…¶ä»–ç±»å‹çš„å¯¹è±¡ï¼Œç›´æ¥å‘é€
              // await self.sendStreamChunk(taskId, targetDeviceId, JSON.stringify(chunk));
              return;
            }
          } else {
            text = String(chunk);
          }

          // é€šè¿‡ handleMessage å‘é€æµå¼æ•°æ®
          await self.sendStreamChunk(taskId, targetDeviceId, text);
        } catch (error) {
          self.logger.error(`Error processing chunk: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
        }
      },

      // æµå¼ç»“æŸæ–¹æ³•
      end: async () => {
      }
    };
  }


  /**
   * å‘é€æµå¼æ•°æ®å—ï¼ˆé€šè¿‡ handleMessageï¼‰
   */
  private async sendStreamChunk(taskId: string, targetDeviceId: string, chunkText: string): Promise<void> {
    const streamMessage: ChatResponseStreamMessage = {
      type: 'chat_response_stream',
      from: this.peerId,
      to: targetDeviceId,
      payload: {
        taskId,
        path: '', // å“åº”æ—¶pathå¯ä»¥ä¸ºç©º
        data: JSON.parse(chunkText) as OllamaChatStreamChunk
      }
    };

    // ä½¿ç”¨ handleMessage è®©ç³»ç»Ÿè‡ªåŠ¨åˆ¤æ–­å‘é€ç›®æ ‡
    await this.tunnel.handleMessage(streamMessage);
  }

  /**
   * å‘é€é”™è¯¯å“åº”
   */
  private async sendErrorResponse(originalMessage: ChatResponseStreamMessage, error: string): Promise<void> {
    const errorMessage: ChatResponseStreamMessage = {
      type: 'chat_response_stream',
      from: this.peerId,
      to: originalMessage.from,
      payload: {
        taskId: originalMessage.payload.taskId,
        path: '', // å“åº”æ—¶pathå¯ä»¥ä¸ºç©º
        data: {
          message: {
            role: 'user',
            content: 'å‘ç”Ÿé”™è¯¯: ' + error
          }, // å“åº”æ—¶messageså¯ä»¥ä¸ºç©º
          done: true
        },
        error,
      }
    };

    await this.tunnel.sendMessage(errorMessage);
  }
}
