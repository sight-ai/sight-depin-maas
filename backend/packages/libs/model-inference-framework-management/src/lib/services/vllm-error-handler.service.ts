import { Injectable, Logger } from '@nestjs/common';
import { VllmMemoryConfig } from './vllm-config.service';

export interface ErrorPattern {
  pattern: RegExp;
  type: string;
  userMessage: string;
  suggestions: string[];
}

export interface ErrorAnalysis {
  type: string;
  userMessage: string;
  suggestions: string[];
  originalError: string;
  recommendations?: Record<string, any>;
}



/**
 * vLLM é”™è¯¯å¤„ç†æœåŠ¡
 * æä¾›é”™è¯¯åˆ†æã€ç”¨æˆ·å‹å¥½æç¤ºå’Œé…ç½®å»ºè®®
 */
@Injectable()
export class VllmErrorHandlerService {
  private readonly logger = new Logger(VllmErrorHandlerService.name);

  private readonly errorPatterns: ErrorPattern[] = [
    {
      pattern: /CUDA out of memory/i,
      type: 'MEMORY_ERROR',
      userMessage: 'æ˜¾å­˜ä¸è¶³ï¼è¯·å°è¯•ä»¥ä¸‹è§£å†³æ–¹æ¡ˆï¼š',
      suggestions: [
        'é™ä½ GPU æ˜¾å­˜åˆ©ç”¨ç‡ (gpu-memory-utilization)',
        'å‡å°‘æœ€å¤§æ¨¡å‹é•¿åº¦ (max-model-len)',
        'å‡å°‘æœ€å¤§å¹¶å‘åºåˆ—æ•° (max-num-seqs)',
        'å¯ç”¨ enforce-eager æ¨¡å¼',
        'å¢åŠ äº¤æ¢ç©ºé—´ (swap-space)'
      ]
    },
    {
      pattern: /Failed to allocate.*bytes/i,
      type: 'ALLOCATION_ERROR',
      userMessage: 'å†…å­˜åˆ†é…å¤±è´¥ï¼å»ºè®®ï¼š',
      suggestions: [
        'æ£€æŸ¥ç³»ç»Ÿå¯ç”¨å†…å­˜',
        'å…³é—­å…¶ä»–å ç”¨å†…å­˜çš„ç¨‹åº',
        'é™ä½æ‰¹å¤„ç†å¤§å° (max-num-batched-tokens)',
        'ä½¿ç”¨é‡åŒ–æ¨¡å‹ (quantization)'
      ]
    },
    {
      pattern: /Model.*not found/i,
      type: 'MODEL_ERROR',
      userMessage: 'æ¨¡å‹æœªæ‰¾åˆ°ï¼è¯·æ£€æŸ¥ï¼š',
      suggestions: [
        'ç¡®è®¤æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®',
        'æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½',
        'éªŒè¯æ¨¡å‹æ ¼å¼æ˜¯å¦æ”¯æŒ',
        'æ£€æŸ¥æ–‡ä»¶æƒé™'
      ]
    },
    {
      pattern: /Port.*already in use/i,
      type: 'PORT_ERROR',
      userMessage: 'ç«¯å£å·²è¢«å ç”¨ï¼è§£å†³æ–¹æ¡ˆï¼š',
      suggestions: [
        'æ›´æ¢å…¶ä»–ç«¯å£å·',
        'åœæ­¢å ç”¨è¯¥ç«¯å£çš„è¿›ç¨‹',
        'æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»– vLLM å®ä¾‹åœ¨è¿è¡Œ'
      ]
    },
    {
      pattern: /Tensor parallel size.*exceeds.*GPU/i,
      type: 'PARALLEL_ERROR',
      userMessage: 'å¼ é‡å¹¶è¡Œé…ç½®é”™è¯¯ï¼',
      suggestions: [
        'å‡å°‘å¼ é‡å¹¶è¡Œå¤§å° (tensor-parallel-size)',
        'ç¡®ä¿å¹¶è¡Œå¤§å°ä¸è¶…è¿‡ GPU æ•°é‡',
        'æ£€æŸ¥ GPU å¯ç”¨æ€§'
      ]
    },
    {
      pattern: /quantization.*not supported/i,
      type: 'QUANTIZATION_ERROR',
      userMessage: 'é‡åŒ–é…ç½®ä¸æ”¯æŒï¼',
      suggestions: [
        'æ£€æŸ¥é‡åŒ–æ–¹æ³•æ˜¯å¦æ­£ç¡® (int8, int4, fp16)',
        'éªŒè¯æ¨¡å‹æ˜¯å¦æ”¯æŒæŒ‡å®šçš„é‡åŒ–æ–¹æ³•',
        'å°è¯•ä¸ä½¿ç”¨é‡åŒ–æˆ–ä½¿ç”¨å…¶ä»–é‡åŒ–æ–¹æ³•'
      ]
    }
  ];

  /**
   * åˆ†æé”™è¯¯æ¶ˆæ¯å¹¶è¿”å›ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯
   */
  analyzeError(errorMessage: string): ErrorAnalysis {
    this.logger.debug(`Analyzing error: ${errorMessage}`);

    for (const pattern of this.errorPatterns) {
      if (pattern.pattern.test(errorMessage)) {
        this.logger.debug(`Matched error pattern: ${pattern.type}`);
        
        return {
          type: pattern.type,
          userMessage: pattern.userMessage,
          suggestions: pattern.suggestions,
          originalError: errorMessage
        };
      }
    }

    this.logger.warn(`Unknown error pattern: ${errorMessage}`);
    
    return {
      type: 'UNKNOWN_ERROR',
      userMessage: 'å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯',
      suggestions: [
        'æ£€æŸ¥ vLLM ç‰ˆæœ¬å…¼å®¹æ€§',
        'æŸ¥çœ‹å®Œæ•´é”™è¯¯æ—¥å¿—',
        'é‡å¯æœåŠ¡åé‡è¯•',
        'è”ç³»æŠ€æœ¯æ”¯æŒ'
      ],
      originalError: errorMessage
    };
  }

  /**
   * ç”Ÿæˆç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
   */
  generateUserFriendlyMessage(errorAnalysis: ErrorAnalysis): string {
    let message = `âŒ ${errorAnalysis.userMessage}\n\n`;
    
    message += 'ğŸ’¡ å»ºè®®çš„è§£å†³æ–¹æ¡ˆï¼š\n';
    errorAnalysis.suggestions.forEach((suggestion, index) => {
      message += `   ${index + 1}. ${suggestion}\n`;
    });

    message += '\nğŸ“‹ æŠ€æœ¯è¯¦æƒ…ï¼š\n';
    message += `   é”™è¯¯ç±»å‹: ${errorAnalysis.type}\n`;
    message += `   åŸå§‹é”™è¯¯: ${errorAnalysis.originalError}\n`;

    return message;
  }

  /**
   * æ ¹æ®é”™è¯¯ç±»å‹è·å–é…ç½®ä¼˜åŒ–å»ºè®®
   */
  getConfigurationRecommendations(errorType: string, currentConfig: VllmMemoryConfig): VllmMemoryConfig {
    const recommendations: VllmMemoryConfig = {};

    switch (errorType) {
      case 'MEMORY_ERROR':
        recommendations.gpuMemoryUtilization = Math.max(0.5, (currentConfig.gpuMemoryUtilization || 0.9) - 0.2);
        recommendations.maxModelLen = Math.max(2048, Math.floor((currentConfig.maxModelLen || 4096) * 0.7));
        recommendations.maxNumSeqs = Math.max(64, Math.floor((currentConfig.maxNumSeqs || 256) * 0.5));
        recommendations.enforceEager = true;
        recommendations.swapSpace = Math.max(4, (currentConfig.swapSpace || 4) + 2);
        break;

      case 'ALLOCATION_ERROR':
        recommendations.maxNumBatchedTokens = Math.max(512, Math.floor((currentConfig.maxNumBatchedTokens || 2048) * 0.5));
        recommendations.blockSize = Math.max(8, (currentConfig.blockSize || 16) - 4);
        recommendations.quantization = 'int8';
        break;

      case 'PARALLEL_ERROR':
        recommendations.tensorParallelSize = 1;
        recommendations.pipelineParallelSize = 1;
        break;

      case 'QUANTIZATION_ERROR':
        recommendations.quantization = null; // ç¦ç”¨é‡åŒ–
        break;

      default:
        // é€šç”¨çš„ä¿å®ˆé…ç½®
        recommendations.gpuMemoryUtilization = 0.7;
        recommendations.maxModelLen = 2048;
        recommendations.maxNumSeqs = 128;
        recommendations.enforceEager = true;
        break;
    }

    this.logger.debug(`Generated recommendations for ${errorType}:`, recommendations);
    return recommendations;
  }

  /**
   * åˆ†æé”™è¯¯å¹¶æä¾›å®Œæ•´çš„è§£å†³æ–¹æ¡ˆ
   */
  analyzeErrorWithRecommendations(errorMessage: string, currentConfig: VllmMemoryConfig): ErrorAnalysis {
    const analysis = this.analyzeError(errorMessage);
    const recommendations = this.getConfigurationRecommendations(analysis.type, currentConfig);
    
    return {
      ...analysis,
      recommendations
    };
  }

  /**
   * æ£€æŸ¥é…ç½®æ˜¯å¦å¯èƒ½å¯¼è‡´å†…å­˜é—®é¢˜
   */
  validateConfigurationRisks(config: VllmMemoryConfig): string[] {
    const warnings: string[] = [];

    if (config.gpuMemoryUtilization && config.gpuMemoryUtilization > 0.9) {
      warnings.push('GPU æ˜¾å­˜åˆ©ç”¨ç‡è¿‡é«˜ (>90%)ï¼Œå¯èƒ½å¯¼è‡´å†…å­˜ä¸è¶³');
    }

    if (config.maxModelLen && config.maxModelLen > 8192) {
      warnings.push('æœ€å¤§æ¨¡å‹é•¿åº¦è¿‡å¤§ï¼Œå¯èƒ½æ¶ˆè€—å¤§é‡æ˜¾å­˜');
    }

    if (config.maxNumSeqs && config.maxNumSeqs > 512) {
      warnings.push('æœ€å¤§å¹¶å‘åºåˆ—æ•°è¿‡å¤šï¼Œå¯èƒ½å¯¼è‡´æ˜¾å­˜ä¸è¶³');
    }

    if (config.enforceEager === false && config.gpuMemoryUtilization && config.gpuMemoryUtilization > 0.8) {
      warnings.push('åœ¨é«˜æ˜¾å­˜åˆ©ç”¨ç‡ä¸‹å»ºè®®å¯ç”¨ enforce-eager æ¨¡å¼');
    }

    return warnings;
  }
}
